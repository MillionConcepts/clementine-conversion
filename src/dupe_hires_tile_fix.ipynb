{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# notebook for changing filenames of dupe hires tiles\n",
    "\n",
    "A handful of tiles in the HIRES mosaic have duplicate pds3 product IDs.\n",
    "This goes through the data set and changes their filenames and pds4\n",
    "LIDs to make them unique."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fs\n",
    "\n",
    "from clem_bulk import crude_time_log\n",
    "from clem_conversion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_mosaic_products = pd.read_csv(\n",
    "    './directories/clementine/standard_mosaic_products.csv'\n",
    ")\n",
    "duped_tiles = standard_mosaic_products.loc[\n",
    "    standard_mosaic_products.duplicated(subset=['pds3_product_id'], keep=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set root directories for your input and output data sets\n",
    "input_root = '/home/ubuntu/buckets/clem_input/'\n",
    "output_root = '/home/ubuntu/buckets/clem_reprocess/'\n",
    "# this roundabout temp directory thing is only necessary to prevent gdal from breaking\n",
    "# when it tries to write directly to a s3fs-fuse 'filesystem'. it would have\n",
    "# no purpose in other configurations.\n",
    "temp_output_directory = '/home/ubuntu/data_temp/'\n",
    "\n",
    "# associate hires source index with an index of edr products that includes time\n",
    "# in order to determine start and stop times for each hires mosaic tile\n",
    "hires_source_groupby = pd.read_csv(\n",
    "    './directories/clementine/hires_source_index.csv',\n",
    ").groupby('tilename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-spotlight",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert all the files in this chunk \n",
    "for ix, tile in enumerate(duped_tiles.itertuples()):\n",
    "    print(\"Converting \" + fs.path.split(tile.file)[1])\n",
    "    \n",
    "    tile_start_time = dt.datetime.now() # just for logging\n",
    "    \n",
    "    source_path = tile.file\n",
    "    source_groups = hires_source_groupby\n",
    "\n",
    "    destination_path = tile.newpath\n",
    "    # just a double-check to avoid any possible extra '/' in S3 object names --\n",
    "    # in some cases it can cause really irritating problems.\n",
    "    if output_root.endswith('/') and destination_path.startswith('/'):\n",
    "        destination_path = destination_path[1:]\n",
    "    sh.mkdir(\"-p\", output_root + destination_path)\n",
    "    volume = source_path[3:7]\n",
    "    \n",
    "    # initialize writer & convert product \n",
    "    writer = ClemMosaicConverter(\n",
    "        input_root + source_path,\n",
    "        source_groups = source_groups\n",
    "    )\n",
    "    \n",
    "    # in case you wrote out unflagged versions before\n",
    "    for extension in ['.xml', '.tif']:\n",
    "        try:\n",
    "            os.remove(\n",
    "                output_root[:-1] + destination_path + writer.pds4_root + extension, \n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print('no existing file')\n",
    "            continue\n",
    "    \n",
    "    writer.pds4_root = writer.pds4_root + '_' + volume\n",
    "    writer.write_pds4(temp_output_directory)\n",
    "    \n",
    "\n",
    "    for extension in ['.xml', '.tif']:\n",
    "        sh.mv(\n",
    "            temp_output_directory + writer.pds4_root + extension, \n",
    "            output_root + destination_path,\n",
    "            _bg=True\n",
    "        )\n",
    "\n",
    "    # very simple logger\n",
    "    elapsed = str((dt.datetime.now() - tile_start_time).total_seconds())\n",
    "    crude_time_log(\n",
    "        'mosaic_conversion_log_hires_dupes.csv',\n",
    "        writer,\n",
    "        elapsed\n",
    "    )\n",
    "    print(\"total seconds: \" + elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}